{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Bank Recommender System Demo\n",
    "## Creating and Deploying AWS Personalize Campaign\n",
    "\n",
    "This notebook demonstrates the process of creating and deploying an AWS Personalize campaign using the Santander dataset we prepared earlier. We'll go through the following steps:\n",
    "\n",
    "1. Set up the AWS Personalize client\n",
    "2. Create a dataset group\n",
    "3. Define schemas and create datasets\n",
    "4. Create and start import jobs for each dataset\n",
    "5. Create a solution (train a model)\n",
    "6. Create a campaign (deploy the model)\n",
    "\n",
    "This process will result in a deployed recommendation model that we can use to generate personalized product recommendations for Santander Bank customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Personalize client\n",
    "personalize = boto3.client('personalize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to wait for a resource to be in the specified state\n",
    "def wait_for_resource(resource_arn, desired_status):\n",
    "    while True:\n",
    "        response = personalize.describe_dataset_group(datasetGroupArn=resource_arn)\n",
    "        status = response['datasetGroup']['status']\n",
    "        if status == desired_status:\n",
    "            print(f\"Resource {resource_arn} is now in {desired_status} state\")\n",
    "            break\n",
    "        elif status == 'CREATE FAILED':\n",
    "            print(f\"Resource {resource_arn} creation failed\")\n",
    "            break\n",
    "        print(f\"Resource {resource_arn} is in {status} state. Waiting...\")\n",
    "        time.sleep(60)  # Wait for 60 seconds before checking again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a Dataset Group\n",
    "\n",
    "A dataset group is a container for Amazon Personalize components, including datasets, event trackers, solutions, filters, campaigns, and batch inference jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource arn:aws:personalize:us-east-1:279988746206:dataset-group/SantanderRecommender2 is in CREATE PENDING state. Waiting...\n",
      "Resource arn:aws:personalize:us-east-1:279988746206:dataset-group/SantanderRecommender2 is now in ACTIVE state\n"
     ]
    }
   ],
   "source": [
    "dataset_group_name = \"SantanderRecommender2\"\n",
    "response = personalize.create_dataset_group(name=dataset_group_name)\n",
    "dataset_group_arn = response['datasetGroupArn']\n",
    "wait_for_resource(dataset_group_arn, 'ACTIVE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Schemas and Create Datasets\n",
    "\n",
    "We need to define schemas for our Users, Items, and Interactions datasets. These schemas should match the structure of the CSV files we prepared earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas = {\n",
    "    'Users': {\n",
    "        \"name\": \"UserSchema\",\n",
    "        \"schema\": json.dumps({\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"Users\",\n",
    "            \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "            \"fields\": [\n",
    "                {\"name\": \"USER_ID\", \"type\": \"string\"},\n",
    "                {\"name\": \"AGE\", \"type\": \"int\"},\n",
    "                {\"name\": \"CUSTOMER_TENURE\", \"type\": \"int\"},\n",
    "                {\"name\": \"INCOME\", \"type\": \"float\"}\n",
    "            ],\n",
    "            \"version\": \"1.0\"\n",
    "        })\n",
    "    },\n",
    "    'Items': {\n",
    "        \"name\": \"ItemSchema\",\n",
    "        \"schema\": json.dumps({\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"Items\",\n",
    "            \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "            \"fields\": [\n",
    "                {\"name\": \"ITEM_ID\", \"type\": \"string\"},\n",
    "                {\n",
    "                    \"name\": \"PRODUCT_DESCRIPTION\",\n",
    "                    \"type\": \"string\",\n",
    "                    \"categorical\": True\n",
    "                }\n",
    "            ],\n",
    "            \"version\": \"1.0\"\n",
    "        })\n",
    "    },\n",
    "    'Interactions': {\n",
    "        \"name\": \"InteractionSchema\",\n",
    "        \"schema\": json.dumps({\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"Interactions\",\n",
    "            \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "            \"fields\": [\n",
    "                {\"name\": \"USER_ID\", \"type\": \"string\"},\n",
    "                {\"name\": \"ITEM_ID\", \"type\": \"string\"},\n",
    "                {\"name\": \"TIMESTAMP\", \"type\": \"long\"},\n",
    "                {\"name\": \"EVENT_TYPE\", \"type\": \"string\"}\n",
    "            ],\n",
    "            \"version\": \"1.0\"\n",
    "        })\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for dataset_type, schema_info in schemas.items():\n",
    "    try:\n",
    "        print(f\"Creating a schema for {dataset_type}\")\n",
    "        create_schema_response = personalize.create_schema(\n",
    "            name=schema_info['name'],\n",
    "            schema=schema_info['schema']\n",
    "        )\n",
    "        schema_arn = create_schema_response['schemaArn']\n",
    "    \n",
    "        # Create dataset\n",
    "        create_dataset_response = personalize.create_dataset(\n",
    "            name=f\"{dataset_type.capitalize()}Dataset\",\n",
    "            schemaArn=schema_arn,\n",
    "            datasetGroupArn=dataset_group_arn,\n",
    "            datasetType=dataset_type.upper()\n",
    "        )\n",
    "        datasets[dataset_type] = create_dataset_response['datasetArn']\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating schema or dataset for {dataset_type}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create and Start Import Jobs for Each Dataset\n",
    "\n",
    "Now that we have created our datasets, we need to import the data from our S3 bucket into these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset import job for  Users\n",
      "Creating dataset import job for  Items\n",
      "Creating dataset import job for  Interactions\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'souhail-work-bucket-1'\n",
    "folder = 'personalize-data'\n",
    "iam_role_arn = 'arn:aws:iam::279988746206:role/PersonalizeServiceRole'\n",
    "\n",
    "for dataset_type, dataset_arn in datasets.items():\n",
    "    try:\n",
    "        print(f\"Creating dataset import job for {dataset_type}\")\n",
    "        job_name = f\"{dataset_type.capitalize()}ImportJob\"\n",
    "        data_location = f\"s3://{bucket_name}/{folder}/{dataset_type}.csv\"\n",
    "        \n",
    "        response = personalize.create_dataset_import_job(\n",
    "            jobName=job_name,\n",
    "            datasetArn=dataset_arn,\n",
    "            dataSource={'dataLocation': data_location},\n",
    "            roleArn=iam_role_arn\n",
    "        )\n",
    "        # Note: In a production environment, you should wait for each import job to complete\n",
    "        # before proceeding to the next step\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating import job for {dataset_type}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a Solution (Train a Model)\n",
    "\n",
    "A solution is the term used in Amazon Personalize for a trained model. We'll use the User-Personalization recipe, which is suitable for generating personalized recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_name = \"SantanderSolutionv2\"\n",
    "recipe_arn = \"arn:aws:personalize:::recipe/aws-user-personalization-v2\"  # User-Personalization recipe\n",
    "\n",
    "create_solution_response = personalize.create_solution(\n",
    "    name=solution_name,\n",
    "    datasetGroupArn=dataset_group_arn,\n",
    "    recipeArn=recipe_arn\n",
    ")\n",
    "solution_arn = create_solution_response['solutionArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a solution version (train the model)\n",
    "create_solution_version_response = personalize.create_solution_version(solutionArn=solution_arn)\n",
    "solution_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "\n",
    "# Note: Training a model can take a significant amount of time. In a production environment,\n",
    "# we should implement a waiting mechanism to check when the solution version is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create a Campaign (Deploy the Model)\n",
    "\n",
    "Finally, we'll create a campaign, which deploys our trained model and makes it available for generating recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_name = \"SantanderCampaign\"\n",
    "create_campaign_response = personalize.create_campaign(\n",
    "    name=campaign_name,\n",
    "    solutionVersionArn=solution_version_arn,\n",
    "    minProvisionedTPS=1  # Minimum number of transactions per second that the campaign can support\n",
    ")\n",
    "campaign_arn = create_campaign_response['campaignArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaign created successfully. Campaign ARN: arn:aws:personalize:us-east-1:279988746206:campaign/SantanderCampaign\n"
     ]
    }
   ],
   "source": [
    "print(f\"Campaign created successfully. Campaign ARN: {campaign_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have successfully created and deployed an AWS Personalize campaign for the Santander Bank recommender system. Here's a summary of what we've accomplished:\n",
    "\n",
    "1. Created a dataset group\n",
    "2. Defined schemas and created datasets for Users, Items, and Interactions\n",
    "3. Imported our prepared data into these datasets\n",
    "4. Created a solution (trained model) using the User-Personalization recipe\n",
    "5. Deployed the model as a campaign\n",
    "\n",
    "Remember to keep an eye on your AWS usage and costs, especially when working with large datasets or high-traffic recommendation scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
