{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Bank Recommender System Demo\n",
    "## Data Preparation for AWS Personalize\n",
    "\n",
    "This notebook is the first step in creating a demo bank recommender system using AWS Personalize with the Kaggle Santander dataset. We'll prepare the three required datasets for AWS Personalize:\n",
    "\n",
    "1. Users Dataset\n",
    "2. Items Dataset\n",
    "3. Interactions Dataset\n",
    "\n",
    "These datasets will be derived from the raw Santander dataset file downloaded from kaggle and stored in S3: \n",
    "https://www.kaggle.com/competitions/santander-product-recommendation/code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set pandas display options for better output readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a session using Amazon S3\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_591/2996586977.py:12: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(local_file_path)\n"
     ]
    }
   ],
   "source": [
    "# Set up your S3 bucket and file name\n",
    "bucket_name = 'souhail-work-bucket'\n",
    "file_key = 'personalize_santander_raw_data/train_ver2.csv'  # Change this to your actual file path in the S3 bucket\n",
    "local_file_path = 'train_ver2.csv'   # Local file path where we want to save the file\n",
    "\n",
    "\n",
    "# Download the file from S3 to the local file system\n",
    "with open(local_file_path, 'wb') as f:\n",
    "    s3.download_fileobj(bucket_name, file_key, f)\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv(local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "655070832"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of the dataset\n",
    "df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is quite large. For demo purposes and to reduce processing time, we'll sample a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the dataset for faster processing\n",
    "# Note: In a production environment, you might want to use the full dataset\n",
    "df = df.sample(n=1000000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          fecha_dato  ncodpers ind_empleado pais_residencia sexo  age  \\\n",
      "2406613   2015-04-28    886976            N              ES    H   49   \n",
      "6466267   2015-10-28    950206            N              ES    H   24   \n",
      "10239289  2016-02-28    474137            N              ES    V   58   \n",
      "6681075   2015-10-28   1236387            N              ES    V   34   \n",
      "2305701   2015-04-28   1359789            N              ES    H   22   \n",
      "\n",
      "          fecha_alta  ind_nuevo antiguedad  indrel ult_fec_cli_1t indrel_1mes  \\\n",
      "2406613   2010-07-27        0.0         60     1.0            NaN         1.0   \n",
      "6466267   2011-09-28        0.0         49     1.0            NaN         1.0   \n",
      "10239289  2004-05-14        0.0        141     1.0            NaN         1.0   \n",
      "6681075   2014-01-07        0.0         21     1.0            NaN         1.0   \n",
      "2305701   2014-11-24        0.0          8     1.0            NaN         1.0   \n",
      "\n",
      "         tiprel_1mes indresi indext conyuemp canal_entrada indfall  tipodom  \\\n",
      "2406613            A       S      N      NaN           KAT       N      1.0   \n",
      "6466267            I       S      N      NaN           KHE       N      1.0   \n",
      "10239289           I       S      N      NaN           KFA       N      1.0   \n",
      "6681075            I       S      N      NaN           KFC       N      1.0   \n",
      "2305701            I       S      N      NaN           KHE       N      1.0   \n",
      "\n",
      "          cod_prov    nomprov  ind_actividad_cliente      renta  \\\n",
      "2406613        9.0     BURGOS                    1.0   98343.03   \n",
      "6466267        6.0    BADAJOZ                    0.0        NaN   \n",
      "10239289      28.0     MADRID                    0.0        NaN   \n",
      "6681075       12.0  CASTELLON                    0.0        NaN   \n",
      "2305701       30.0     MURCIA                    0.0  126999.66   \n",
      "\n",
      "                    segmento  ind_ahor_fin_ult1  ind_aval_fin_ult1  \\\n",
      "2406613    02 - PARTICULARES                  0                  0   \n",
      "6466267   03 - UNIVERSITARIO                  0                  0   \n",
      "10239289   02 - PARTICULARES                  0                  0   \n",
      "6681075    02 - PARTICULARES                  0                  0   \n",
      "2305701   03 - UNIVERSITARIO                  0                  0   \n",
      "\n",
      "          ind_cco_fin_ult1  ind_cder_fin_ult1  ind_cno_fin_ult1  \\\n",
      "2406613                  0                  0                 1   \n",
      "6466267                  1                  0                 0   \n",
      "10239289                 0                  0                 0   \n",
      "6681075                  1                  0                 0   \n",
      "2305701                  1                  0                 0   \n",
      "\n",
      "          ind_ctju_fin_ult1  ind_ctma_fin_ult1  ind_ctop_fin_ult1  \\\n",
      "2406613                   0                  1                  0   \n",
      "6466267                   0                  0                  0   \n",
      "10239289                  0                  0                  0   \n",
      "6681075                   0                  0                  0   \n",
      "2305701                   0                  0                  0   \n",
      "\n",
      "          ind_ctpp_fin_ult1  ind_deco_fin_ult1  ind_deme_fin_ult1  \\\n",
      "2406613                   0                  0                  0   \n",
      "6466267                   0                  0                  0   \n",
      "10239289                  0                  0                  0   \n",
      "6681075                   0                  0                  0   \n",
      "2305701                   0                  0                  0   \n",
      "\n",
      "          ind_dela_fin_ult1  ind_ecue_fin_ult1  ind_fond_fin_ult1  \\\n",
      "2406613                   0                  1                  0   \n",
      "6466267                   0                  0                  0   \n",
      "10239289                  0                  0                  0   \n",
      "6681075                   0                  0                  0   \n",
      "2305701                   0                  0                  0   \n",
      "\n",
      "          ind_hip_fin_ult1  ind_plan_fin_ult1  ind_pres_fin_ult1  \\\n",
      "2406613                  0                  0                  0   \n",
      "6466267                  0                  0                  0   \n",
      "10239289                 0                  0                  0   \n",
      "6681075                  0                  0                  0   \n",
      "2305701                  0                  0                  0   \n",
      "\n",
      "          ind_reca_fin_ult1  ind_tjcr_fin_ult1  ind_valo_fin_ult1  \\\n",
      "2406613                   0                  1                  0   \n",
      "6466267                   0                  0                  0   \n",
      "10239289                  0                  0                  0   \n",
      "6681075                   0                  0                  0   \n",
      "2305701                   0                  0                  0   \n",
      "\n",
      "          ind_viv_fin_ult1  ind_nomina_ult1  ind_nom_pens_ult1  \\\n",
      "2406613                  0              0.0                0.0   \n",
      "6466267                  0              0.0                0.0   \n",
      "10239289                 0              0.0                0.0   \n",
      "6681075                  0              0.0                0.0   \n",
      "2305701                  0              0.0                0.0   \n",
      "\n",
      "          ind_recibo_ult1  \n",
      "2406613                 0  \n",
      "6466267                 0  \n",
      "10239289                0  \n",
      "6681075                 0  \n",
      "2305701                 0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000000 entries, 2406613 to 13476521\n",
      "Data columns (total 48 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   fecha_dato             1000000 non-null  object \n",
      " 1   ncodpers               1000000 non-null  int64  \n",
      " 2   ind_empleado           997936 non-null   object \n",
      " 3   pais_residencia        997936 non-null   object \n",
      " 4   sexo                   997930 non-null   object \n",
      " 5   age                    1000000 non-null  object \n",
      " 6   fecha_alta             997936 non-null   object \n",
      " 7   ind_nuevo              997936 non-null   float64\n",
      " 8   antiguedad             1000000 non-null  object \n",
      " 9   indrel                 997936 non-null   float64\n",
      " 10  ult_fec_cli_1t         1809 non-null     object \n",
      " 11  indrel_1mes            989036 non-null   object \n",
      " 12  tiprel_1mes            989036 non-null   object \n",
      " 13  indresi                997936 non-null   object \n",
      " 14  indext                 997936 non-null   object \n",
      " 15  conyuemp               130 non-null      object \n",
      " 16  canal_entrada          986417 non-null   object \n",
      " 17  indfall                997936 non-null   object \n",
      " 18  tipodom                997936 non-null   float64\n",
      " 19  cod_prov               993111 non-null   float64\n",
      " 20  nomprov                993111 non-null   object \n",
      " 21  ind_actividad_cliente  997936 non-null   float64\n",
      " 22  renta                  795536 non-null   float64\n",
      " 23  segmento               986177 non-null   object \n",
      " 24  ind_ahor_fin_ult1      1000000 non-null  int64  \n",
      " 25  ind_aval_fin_ult1      1000000 non-null  int64  \n",
      " 26  ind_cco_fin_ult1       1000000 non-null  int64  \n",
      " 27  ind_cder_fin_ult1      1000000 non-null  int64  \n",
      " 28  ind_cno_fin_ult1       1000000 non-null  int64  \n",
      " 29  ind_ctju_fin_ult1      1000000 non-null  int64  \n",
      " 30  ind_ctma_fin_ult1      1000000 non-null  int64  \n",
      " 31  ind_ctop_fin_ult1      1000000 non-null  int64  \n",
      " 32  ind_ctpp_fin_ult1      1000000 non-null  int64  \n",
      " 33  ind_deco_fin_ult1      1000000 non-null  int64  \n",
      " 34  ind_deme_fin_ult1      1000000 non-null  int64  \n",
      " 35  ind_dela_fin_ult1      1000000 non-null  int64  \n",
      " 36  ind_ecue_fin_ult1      1000000 non-null  int64  \n",
      " 37  ind_fond_fin_ult1      1000000 non-null  int64  \n",
      " 38  ind_hip_fin_ult1       1000000 non-null  int64  \n",
      " 39  ind_plan_fin_ult1      1000000 non-null  int64  \n",
      " 40  ind_pres_fin_ult1      1000000 non-null  int64  \n",
      " 41  ind_reca_fin_ult1      1000000 non-null  int64  \n",
      " 42  ind_tjcr_fin_ult1      1000000 non-null  int64  \n",
      " 43  ind_valo_fin_ult1      1000000 non-null  int64  \n",
      " 44  ind_viv_fin_ult1       1000000 non-null  int64  \n",
      " 45  ind_nomina_ult1        998799 non-null   float64\n",
      " 46  ind_nom_pens_ult1      998799 non-null   float64\n",
      " 47  ind_recibo_ult1        1000000 non-null  int64  \n",
      "dtypes: float64(8), int64(23), object(17)\n",
      "memory usage: 373.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows and basic information about the dataset\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "\n",
    "# This gives us an overview of the data types and non-null counts for each column.\n",
    "# We'll use this information to decide which features to include in our datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Users Dataset\n",
    "\n",
    "The Users dataset will contain information about each customer. We'll select relevant features that could influence product recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          USER_ID  AGE CUSTOMER_TENURE     INCOME  NEW_CUSTOMER  \\\n",
      "2406613    886976   49              60   98343.03           0.0   \n",
      "6466267    950206   24              49        NaN           0.0   \n",
      "10239289   474137   58             141        NaN           0.0   \n",
      "6681075   1236387   34              21        NaN           0.0   \n",
      "2305701   1359789   22               8  126999.66           0.0   \n",
      "\n",
      "                     SEGMENT EMPLOYEE_INDEX COUNTRY_RESIDENCE SEX  \\\n",
      "2406613    02 - PARTICULARES              N                ES   H   \n",
      "6466267   03 - UNIVERSITARIO              N                ES   H   \n",
      "10239289   02 - PARTICULARES              N                ES   V   \n",
      "6681075    02 - PARTICULARES              N                ES   V   \n",
      "2305701   03 - UNIVERSITARIO              N                ES   H   \n",
      "\n",
      "          CUSTOMER_ACTIVITY_INDEX PROVINCE_NAME  ACCOUNT_AGE_DAYS  \n",
      "2406613                       1.0        BURGOS            1797.0  \n",
      "6466267                       0.0       BADAJOZ            1369.0  \n",
      "10239289                      0.0        MADRID            4062.0  \n",
      "6681075                       0.0     CASTELLON             537.0  \n",
      "2305701                       0.0        MURCIA             216.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 953604 entries, 2406613 to 13476521\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   USER_ID                  953604 non-null  object \n",
      " 1   AGE                      953604 non-null  object \n",
      " 2   CUSTOMER_TENURE          953604 non-null  object \n",
      " 3   INCOME                   757130 non-null  float64\n",
      " 4   NEW_CUSTOMER             951807 non-null  float64\n",
      " 5   SEGMENT                  940049 non-null  object \n",
      " 6   EMPLOYEE_INDEX           951807 non-null  object \n",
      " 7   COUNTRY_RESIDENCE        951807 non-null  object \n",
      " 8   SEX                      951801 non-null  object \n",
      " 9   CUSTOMER_ACTIVITY_INDEX  951807 non-null  float64\n",
      " 10  PROVINCE_NAME            947272 non-null  object \n",
      " 11  ACCOUNT_AGE_DAYS         951807 non-null  float64\n",
      "dtypes: float64(4), object(8)\n",
      "memory usage: 94.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Prepare User dataset with additional features\n",
    "def prepare_user_dataset(df):\n",
    "    user_df = df[['ncodpers', 'age', 'antiguedad', 'renta', 'ind_nuevo', 'segmento', \n",
    "                  'ind_empleado', 'pais_residencia', 'sexo', 'fecha_alta', \n",
    "                  'ind_actividad_cliente', 'nomprov']].drop_duplicates()\n",
    "    \n",
    "    user_df.columns = ['USER_ID', 'AGE', 'CUSTOMER_TENURE', 'INCOME', 'NEW_CUSTOMER', \n",
    "                       'SEGMENT', 'EMPLOYEE_INDEX', 'COUNTRY_RESIDENCE', 'SEX', \n",
    "                       'FIRST_HOLD_DATE', 'CUSTOMER_ACTIVITY_INDEX', 'PROVINCE_NAME']\n",
    "    \n",
    "    user_df['USER_ID'] = user_df['USER_ID'].astype(str)\n",
    "    \n",
    "    # Convert 'FIRST_HOLD_DATE' to datetime and calculate account age\n",
    "    user_df['FIRST_HOLD_DATE'] = pd.to_datetime(user_df['FIRST_HOLD_DATE'])\n",
    "    user_df['ACCOUNT_AGE_DAYS'] = (pd.Timestamp('2015-06-28') - user_df['FIRST_HOLD_DATE']).dt.days\n",
    "    \n",
    "    # Drop the original 'FIRST_HOLD_DATE' column\n",
    "    user_df = user_df.drop('FIRST_HOLD_DATE', axis=1)\n",
    "    \n",
    "    return user_df\n",
    "\n",
    "user_dataset = prepare_user_dataset(df)\n",
    "print(user_dataset.head())\n",
    "print(user_dataset.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of User Dataset Columns\n",
    "\n",
    "- USER_ID: Unique identifier for each user\n",
    "- AGE: User's age\n",
    "- CUSTOMER_TENURE: How long the customer has been with the bank\n",
    "- INCOME: Customer's income\n",
    "- NEW_CUSTOMER: Indicates if the customer is new\n",
    "- SEGMENT: Customer segmentation category\n",
    "- EMPLOYEE_INDEX: Indicates if the customer is an employee\n",
    "- COUNTRY_RESIDENCE: Customer's country of residence\n",
    "- SEX: Customer's gender\n",
    "- CUSTOMER_ACTIVITY_INDEX: Index of customer activity\n",
    "- PROVINCE_NAME: Name of the province\n",
    "- ACCOUNT_AGE_DAYS: Number of days since the account was opened\n",
    "\n",
    "These features provide a comprehensive profile of each customer, which AWS Personalize can use to generate more accurate recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Items Dataset\n",
    "\n",
    "The Items dataset will contain information about each product offered by the bank. In this case, our items are the various financial products indicated by the 'ind_*_fin_ult1' columns in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ITEM_ID    PRODUCT_DESCRIPTION\n",
      "0   ind_ahor_fin_ult1                Savings\n",
      "1   ind_aval_fin_ult1             Guarantees\n",
      "2    ind_cco_fin_ult1         CurrentAccount\n",
      "3   ind_cder_fin_ult1            Derivatives\n",
      "4    ind_cno_fin_ult1         PayrollAccount\n",
      "5   ind_ctju_fin_ult1          JuniorAccount\n",
      "6   ind_ctma_fin_ult1             MasAccount\n",
      "7   ind_ctop_fin_ult1      ParticularAccount\n",
      "8   ind_ctpp_fin_ult1  ParticularPlusAccount\n",
      "9   ind_deco_fin_ult1           ShortDeposit\n",
      "10  ind_deme_fin_ult1          MediumDeposit\n",
      "11  ind_dela_fin_ult1            LongDeposit\n",
      "12  ind_ecue_fin_ult1               eAccount\n",
      "13  ind_fond_fin_ult1                  Funds\n",
      "14   ind_hip_fin_ult1               Mortgage\n",
      "15  ind_plan_fin_ult1               Pensions\n",
      "16  ind_pres_fin_ult1                  Loans\n",
      "17  ind_reca_fin_ult1                  Taxes\n",
      "18  ind_tjcr_fin_ult1             CreditCard\n",
      "19  ind_valo_fin_ult1             Securities\n",
      "20   ind_viv_fin_ult1            HomeAccount\n",
      "21    ind_nomina_ult1                Payroll\n",
      "22  ind_nom_pens_ult1        PensionPayments\n",
      "23    ind_recibo_ult1            DirectDebit\n"
     ]
    }
   ],
   "source": [
    "# Prepare Items dataset\n",
    "def prepare_items_dataset(df):\n",
    "    product_columns = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "                       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
    "                       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "                       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "                       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "                       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "                       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "                       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "    \n",
    "    items_df = pd.DataFrame({'ITEM_ID': product_columns})\n",
    "    \n",
    "    # Dictionary mapping product codes to explicit English descriptions\n",
    "    product_descriptions = {\n",
    "        'ind_ahor_fin_ult1': 'Savings',\n",
    "        'ind_aval_fin_ult1': 'Guarantees',\n",
    "        'ind_cco_fin_ult1': 'CurrentAccount',\n",
    "        'ind_cder_fin_ult1': 'Derivatives',\n",
    "        'ind_cno_fin_ult1': 'PayrollAccount',\n",
    "        'ind_ctju_fin_ult1': 'JuniorAccount',\n",
    "        'ind_ctma_fin_ult1': 'MasAccount',\n",
    "        'ind_ctop_fin_ult1': 'ParticularAccount',\n",
    "        'ind_ctpp_fin_ult1': 'ParticularPlusAccount',\n",
    "        'ind_deco_fin_ult1': 'ShortDeposit',\n",
    "        'ind_deme_fin_ult1': 'MediumDeposit',\n",
    "        'ind_dela_fin_ult1': 'LongDeposit',\n",
    "        'ind_ecue_fin_ult1': 'eAccount',\n",
    "        'ind_fond_fin_ult1': 'Funds',\n",
    "        'ind_hip_fin_ult1': 'Mortgage',\n",
    "        'ind_plan_fin_ult1': 'Pensions',\n",
    "        'ind_pres_fin_ult1': 'Loans',\n",
    "        'ind_reca_fin_ult1': 'Taxes',\n",
    "        'ind_tjcr_fin_ult1': 'CreditCard',\n",
    "        'ind_valo_fin_ult1': 'Securities',\n",
    "        'ind_viv_fin_ult1': 'HomeAccount',\n",
    "        'ind_nomina_ult1': 'Payroll',\n",
    "        'ind_nom_pens_ult1': 'PensionPayments',\n",
    "        'ind_recibo_ult1': 'DirectDebit'\n",
    "    }\n",
    "    \n",
    "    items_df['PRODUCT_DESCRIPTION'] = items_df['ITEM_ID'].map(product_descriptions)\n",
    "    \n",
    "    return items_df\n",
    "\n",
    "items_dataset = prepare_items_dataset(df)\n",
    "print(items_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Items Dataset\n",
    "\n",
    "The Items dataset contains two columns:\n",
    "- ITEM_ID: Unique identifier for each product (corresponds to the original column names)\n",
    "- PRODUCT_DESCRIPTION: A more readable description of the product\n",
    "\n",
    "This dataset provides a clear mapping between the product codes used in the interactions and their actual descriptions, which will be useful for interpreting the recommendations generated by AWS Personalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Interactions Dataset\n",
    "\n",
    "The Interactions dataset will contain information about which products each user has. In this dataset, we'll consider a product as 'interacted with' if the corresponding column in the original dataset has a value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  USER_ID            ITEM_ID   TIMESTAMP EVENT_TYPE\n",
      "0  886976   ind_cno_fin_ult1  1430179200   purchase\n",
      "1  886976  ind_ctma_fin_ult1  1430179200   purchase\n",
      "2  886976  ind_ecue_fin_ult1  1430179200   purchase\n",
      "3  886976  ind_tjcr_fin_ult1  1430179200   purchase\n",
      "4  950206   ind_cco_fin_ult1  1445990400   purchase\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1461842 entries, 0 to 1461841\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   USER_ID     1461842 non-null  object\n",
      " 1   ITEM_ID     1461842 non-null  object\n",
      " 2   TIMESTAMP   1461842 non-null  int64 \n",
      " 3   EVENT_TYPE  1461842 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 44.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Prepare Interactions dataset\n",
    "def prepare_interactions_dataset(df, items_df):\n",
    "    interactions = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        user_id = str(row['ncodpers'])\n",
    "        timestamp = int(datetime.strptime(row['fecha_dato'], '%Y-%m-%d').timestamp())\n",
    "        \n",
    "        for item_id in items_df['ITEM_ID']:\n",
    "            if row[item_id] == 1:\n",
    "                interactions.append({\n",
    "                    'USER_ID': user_id,\n",
    "                    'ITEM_ID': item_id,\n",
    "                    'TIMESTAMP': timestamp,\n",
    "                    'EVENT_TYPE': 'purchase'\n",
    "                })\n",
    "    \n",
    "    interactions_df = pd.DataFrame(interactions)\n",
    "    return interactions_df\n",
    "\n",
    "interactions_dataset = prepare_interactions_dataset(df, items_dataset)\n",
    "print(interactions_dataset.head())\n",
    "print(interactions_dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Interactions Dataset\n",
    "\n",
    "The Interactions dataset contains four columns:\n",
    "- USER_ID: Identifies the user involved in the interaction\n",
    "- ITEM_ID: Identifies the product involved in the interaction\n",
    "- TIMESTAMP: The time when the interaction occurred (converted to Unix timestamp)\n",
    "- EVENT_TYPE: Type of interaction (in this case, always 'purchase')\n",
    "\n",
    "This dataset captures the relationship between users and products. Each row represents a user having a specific product (indicated by a '1' in the original dataset), which we interpret as a 'purchase' event.\n",
    "\n",
    "Note: In this simplified model, we're treating all product ownerships as 'purchases' at the time recorded in the dataset. In a more sophisticated model, you might want to differentiate between different types of interactions or track changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets exported to CSV files.\n"
     ]
    }
   ],
   "source": [
    "# Export datasets to CSV locally\n",
    "user_dataset.to_csv('users.csv', index=False)\n",
    "items_dataset.to_csv('items.csv', index=False)\n",
    "interactions_dataset.to_csv('interactions.csv', index=False)\n",
    "\n",
    "print(\"Datasets exported to CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved personalize-data/users.csv to S3 bucket souhail-work-bucket\n",
      "Saved personalize-data/items.csv to S3 bucket souhail-work-bucket\n",
      "Saved personalize-data/interactions.csv to S3 bucket souhail-work-bucket\n",
      "All datasets have been successfully saved to S3.\n",
      "\n",
      "S3 URLs for your datasets:\n",
      "Users dataset: s3://souhail-work-bucket/personalize-data/Users.csv\n",
      "Items dataset: s3://souhail-work-bucket/personalize-data/Items.csv\n",
      "Interactions dataset: s3://souhail-work-bucket/personalize-data/Interactions.csv\n",
      "\n",
      "Contents of S3 bucket:\n",
      "- personalize-data/Interactions.csv\n",
      "- personalize-data/Items.csv\n",
      "- personalize-data/Users.csv\n",
      "- personalize-data/interactions.csv\n",
      "- personalize-data/items.csv\n",
      "- personalize-data/users.csv\n"
     ]
    }
   ],
   "source": [
    "# Export datasets to CSV on S3\n",
    "bucket_name = 'souhail-work-bucket'\n",
    "\n",
    "def dataframe_to_s3(df, bucket, key):\n",
    "    \"\"\"\n",
    "    Save a pandas DataFrame to S3 as a CSV file\n",
    "    \"\"\"\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    s3.put_object(Bucket=bucket, Key=key, Body=csv_buffer.getvalue())\n",
    "    print(f\"Saved {key} to S3 bucket {bucket}\")\n",
    "\n",
    "\n",
    "# Save datasets to S3\n",
    "dataframe_to_s3(user_dataset, bucket_name, 'personalize-data/Users.csv')\n",
    "dataframe_to_s3(items_dataset, bucket_name, 'personalize-data/Items.csv')\n",
    "dataframe_to_s3(interactions_dataset, bucket_name, 'personalize-data/Interactions.csv')\n",
    "\n",
    "print(\"All datasets have been successfully saved to S3.\")\n",
    "\n",
    "# Generate S3 URLs for the datasets\n",
    "s3_base_url = f\"s3://{bucket_name}/personalize-data/\"\n",
    "print(f\"\\nS3 URLs for your datasets:\")\n",
    "print(f\"Users dataset: {s3_base_url}Users.csv\")\n",
    "print(f\"Items dataset: {s3_base_url}Items.csv\")\n",
    "print(f\"Interactions dataset: {s3_base_url}Interactions.csv\")\n",
    "\n",
    "# Optional: List contents of the S3 bucket to verify\n",
    "response = s3.list_objects_v2(Bucket=bucket_name, Prefix='personalize-data/')\n",
    "print(\"\\nContents of S3 bucket:\")\n",
    "for obj in response.get('Contents', []):\n",
    "    print(f\"- {obj['Key']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have successfully prepared three datasets for use with AWS Personalize:\n",
    "\n",
    "1. Users Dataset: Contains information about each customer\n",
    "2. Items Dataset: Contains information about each product offered by the bank\n",
    "3. Interactions Dataset: Contains information about which products each user has\n",
    "\n",
    "These datasets are now ready to be uploaded to Amazon S3 and used to create a recommendation model in AWS Personalize.\n",
    "\n",
    "Next steps:\n",
    "1. Create a dataset group in AWS Personalize\n",
    "2. Import the datasets into AWS Personalize\n",
    "3. Create and train a recommendation model\n",
    "4. Generate and evaluate recommendations\n",
    "\n",
    "Remember to monitor your AWS usage and costs when working with large datasets and training models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
